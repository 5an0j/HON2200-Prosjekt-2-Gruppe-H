{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f50b2959",
   "metadata": {},
   "source": [
    "Dette programmet gjør en stilistisk analyse av strategiene med embeddings (topografisk analyse, se Toubia et al., 2021). Dette er for å sammenlikne og se om noen skiller seg sterkt fra de andre, men er ikke ellers veldig interessant for våre formål. Det er likevel en betydelig (om noe uinteressant) utvidelse av nøkkelordsanalysen.\n",
    "\n",
    "Også dette programmet tar evigheter å kjøre (først og fremst tar embeddingen lang tid (uten GPU/cuda), og deretter løser vi noen halvtunge optimeringsproblemer (TSP og volumberegninger, se Topography.py))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bfc5f724",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Topography import Topography\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf2509d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "China.txt\n",
      "EU.txt\n",
      "--------------------------------------------------\n",
      "Found no file with extras\n",
      "--------------------------------------------------\n",
      "\n",
      "Poland.txt\n",
      "  Country                                   Embeddings (500)    volume  \\\n",
      "0   China  [[-0.09726964, 0.08906725, -0.09776214, -0.488...  2.003385   \n",
      "1      EU  [[0.030849582, 0.33885244, -1.0729142, 0.29462...  1.922355   \n",
      "2  Poland  [[-0.15160954, -0.050911434, 0.23864263, 0.168...  1.906332   \n",
      "\n",
      "      speed  circuitousness  \n",
      "0  2.433337        0.062631  \n",
      "1  2.311660        0.052566  \n",
      "2  2.360219        0.104344  \n"
     ]
    }
   ],
   "source": [
    "folder = \"./txt\" # change source folder here\n",
    "chunksize = 500 # change chunksize here\n",
    "\n",
    "\n",
    "data = []\n",
    "\n",
    "for filename in os.listdir(folder):\n",
    "    file_path = os.path.join(folder, filename)\n",
    "\n",
    "    if os.path.isfile(file_path):\n",
    "        # Analysis\n",
    "        text = Topography(file_path)\n",
    "        text.embed(chunksize=chunksize)\n",
    "        embeddings = text.embeddings\n",
    "        volume = text.volume()\n",
    "        speed, circuitousness = text.speed()\n",
    "        data.append([filename[:-4], embeddings, volume, speed, circuitousness])\n",
    "\n",
    "        del text\n",
    "        gc.collect() # python's automatic gc is bad\n",
    "\n",
    "        print(filename) # progress bar\n",
    "\n",
    "    else:\n",
    "        msg = \"-\"*50 + f\"\\nFound no file with {filename}\\n\" + \"-\"*50\n",
    "        print(msg)\n",
    "    \n",
    "df = pd.DataFrame(data, columns=['Country', f'Embeddings ({chunksize})', 'volume', 'speed', 'circuitousness'])\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2479e1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle(\"embeddings.pkl\") # pickle to avoid stringifying arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3057c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Animations using code from Toppography, potentially usable for presentation.\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import io\n",
    "\n",
    "def _HDBSCAN_clustering(x_2d):\n",
    "    \"\"\"\n",
    "    Uses HDBSCAN do do unsupervised clustering of the points.\n",
    "    \n",
    "    Input is an array of points in 2d.\n",
    "    Output is a list with the color of each point in 2d.\n",
    "    \"\"\"\n",
    "    from sklearn.cluster import HDBSCAN\n",
    "\n",
    "    hdbscan = HDBSCAN(min_cluster_size=5, min_samples=5) # Initializing the HDBSCAN model\n",
    "    clusters = hdbscan.fit_predict(x_2d) # Using HBDSCAN to cluster the points\n",
    "\n",
    "    # Finding the number of clusters:\n",
    "    if -1 in clusters:\n",
    "        num_colors = len(set(clusters)) - 1 # -1 (no cluster) should not be included in the count of clusters\n",
    "    else:\n",
    "        num_colors = len(set(clusters))\n",
    "\n",
    "    colormap = matplotlib.colormaps['gist_rainbow'] # Specifying the colormap\n",
    "    grey = (0.0, 0.0, 0.0, 1) # Specifying the the color for the points not in a cluster\n",
    "\n",
    "    norm = mcolors.Normalize(vmin=0, vmax=num_colors) # The cluster indexes must be normalized in order to represent a color\n",
    "\n",
    "    # Assigning a color to each point based on the cluster indexes\n",
    "    color_list = []\n",
    "    for cluster_index in clusters:\n",
    "        if cluster_index == -1: \n",
    "            color_list.append(grey) # The points not in a cluster are black\n",
    "        else:\n",
    "            color_list.append(colormap(norm(cluster_index)))\n",
    "    \n",
    "    return color_list\n",
    "\n",
    "\n",
    "def _reduce_dimensions(perplexity, embeddings):\n",
    "        \"\"\"\n",
    "        Helper. Uses t-SNE to reduce the dimensionality of the embeddings.\n",
    "        Output is an array of points in 2D.\n",
    "        \"\"\"\n",
    "\n",
    "        assert perplexity < len(embeddings), 'The perplexity must be lower than the number of chunks.'\n",
    "\n",
    "        # Importing and initializing the t-SNE model\n",
    "        from sklearn.manifold import TSNE\n",
    "        tsne = TSNE(n_components=2, init=\"pca\", perplexity=perplexity, random_state=42) \n",
    "\n",
    "        # Reducing to 2D\n",
    "        return tsne.fit_transform(embeddings)\n",
    "\n",
    "\n",
    "\n",
    "def animate(destination, embeddings, perplexity=10):\n",
    "    \"\"\"\n",
    "    Uses t-SNE to visualise the embeddings in 2D.\n",
    "    Uses HDBSCAN do do unsupervised clustering of the points.\n",
    "    Makes an animation of the path through the points.\n",
    "\n",
    "    The resulting gif is saved at the path specified by destination.\n",
    "    \"\"\"\n",
    "\n",
    "    x_2d = _reduce_dimensions(perplexity, embeddings) # t-SNE reduction\n",
    "    color_list = _HDBSCAN_clustering(x_2d)\n",
    "\n",
    "    x = x_2d[:, 0]\n",
    "    y = x_2d[:, 1]\n",
    "    x_range = np.ptp(x)\n",
    "    y_range = np.ptp(y)\n",
    "\n",
    "    axis_set = [min(x) - x_range/20, max(x) + x_range/20, min(y) - y_range/20, max(y) + y_range/20] # Calculating suitable axis\n",
    "    plt.figure(figsize=(8, 6)) # Fixing the size of the plot\n",
    "    plt.axis(axis_set) # Fixing the axis of the plot\n",
    "    plt.title('t-SNE animation') # Setting the title of the plot\n",
    "\n",
    "    frames = []\n",
    "    for i, point in enumerate(x_2d):\n",
    "        plt.scatter(point[0], point[1], label=f\"Point {i}\", color=color_list[i]) # Plotting the points\n",
    "\n",
    "        if i > 0:\n",
    "            x_values = [x[i-1], x[i]]\n",
    "            y_values = [y[i-1], y[i]]\n",
    "            plt.plot(x_values, y_values, color='grey', lw=1) # Plotting lines between the points\n",
    "        \n",
    "        # Saving frames as images to IO-stream\n",
    "        buf = io.BytesIO()\n",
    "        plt.savefig(buf, format='png')\n",
    "        buf.seek(0)\n",
    "        frames.append(Image.open(buf))\n",
    "\n",
    "    # Saving frames as GIF\n",
    "    frames[0].save(destination, save_all=True, append_images=frames[1:], duration=400, loop=0)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8c1aa30a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Country                                   Embeddings (500)    volume  \\\n",
      "0   China  [[-0.09726964, 0.08906725, -0.09776214, -0.488...  2.003385   \n",
      "1      EU  [[0.030849582, 0.33885244, -1.0729142, 0.29462...  1.922355   \n",
      "2  Poland  [[-0.15160954, -0.050911434, 0.23864263, 0.168...  1.906332   \n",
      "\n",
      "      speed  circuitousness  \n",
      "0  2.433337        0.062631  \n",
      "1  2.311660        0.052566  \n",
      "2  2.360219        0.104344  \n",
      "China\n",
      "7\n",
      "EU\n",
      "68\n",
      "Poland\n",
      "37\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_pickle('embeddings.pkl')\n",
    "print(df)\n",
    "for name, embeddings in zip(df['Country'], df['Embeddings (500)']):\n",
    "    print(name)\n",
    "    print(len(embeddings))\n",
    "    animate(f\"{name}.gif\", embeddings=embeddings, perplexity=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AIbase",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
